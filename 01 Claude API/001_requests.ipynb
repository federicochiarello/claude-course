{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d715c2-c769-4729-af03-821dd2944766",
   "metadata": {},
   "source": [
    "# Making a Request to Anthropic API\n",
    "\n",
    "Generate an API key using Cluade Console and store it in a .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41319b02-9804-4153-ac76-1e7fcfe1630a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load env variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2161a40a-97a6-4b85-bd96-25a431ea614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create API Client\n",
    "from anthropic import Anthropic\n",
    "\n",
    "client = Anthropic()\n",
    "model = \"claude-sonnet-4-0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49660442-cfd2-402d-817f-4394a4e1d319",
   "metadata": {},
   "source": [
    "## Create Function\n",
    "__max_tokens__ parameter limits the response lenght (as a safety mechanism), but does not act as a target for the models.  \n",
    "If the model's response reaches the max_tokens lenght, it will be truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc3fc199-0716-4925-85a9-1dfa9be8b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a request\n",
    "message = client.messages.create(\n",
    "    model = model,\n",
    "    max_tokens = 1000,\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is a LLM (Large Language Model)? Answer in one sentence\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d42e6a56-1f7c-4a00-9ce6-e36e35059f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_01ToVPUXJq5AVNRwXr3iyhdk', content=[TextBlock(citations=None, text='A Large Language Model (LLM) is an AI system trained on vast amounts of text data that can understand and generate human-like text by predicting the most likely next words in a sequence.', type='text')], model='claude-sonnet-4-20250514', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation=CacheCreation(ephemeral_1h_input_tokens=0, ephemeral_5m_input_tokens=0), cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=23, output_tokens=44, server_tool_use=None, service_tier='standard', inference_geo='not_available'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc522eb2-1052-4915-8420-663bc5004ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Large Language Model (LLM) is an AI system trained on vast amounts of text data that can understand and generate human-like text by predicting the most likely next words in a sequence.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1e266-fb88-4a92-87d5-8164d6d9070e",
   "metadata": {},
   "source": [
    "# Multi-turn Conversations\n",
    "Claude doesn't store any of your conversation history. Each request you make is completely independent, with no memory of previous exchanges.  \n",
    "If you want to have a multi-turn conversation where Claude remembers context from earlier messages, you need to handle the conversation state yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b889ae-5384-44cb-89e3-a47e4830241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user_message(messages, text):\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": text\n",
    "    }\n",
    "    messages.append(user_message)\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": text\n",
    "    }\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "def chat(messages):\n",
    "    message = client.messages.create(\n",
    "        model = model,\n",
    "        max_tokens = 1000,\n",
    "        messages = messages\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae91fb0d-23ef-40e3-b055-885084ed98da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LLMs work by predicting the most likely next word or phrase based on patterns learned from their training data, enabling them to produce coherent and contextually relevant responses across a wide range of topics.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a starting list of messages\n",
    "messages = []\n",
    "\n",
    "# Add in the initial user question\n",
    "add_user_message(messages, \"What is a LLM (Large Language Model)? Answer in one sentence\")\n",
    "\n",
    "# Pass the list of messages into 'chat' to get an answer\n",
    "answer = chat(messages)\n",
    "\n",
    "# Take the answer and add it as an assistant message into our list\n",
    "add_assistant_message(messages, answer)\n",
    "\n",
    "# Add in the user's follow-up question\n",
    "add_user_message(messages, \"Write another sentence\")\n",
    "\n",
    "# Call chat again with the list of messages to get a final answer\n",
    "answer = chat(messages)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5a4559-656f-42d7-ae1d-bb6817699642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'What is a LLM (Large Language Model)? Answer in one sentence'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'A Large Language Model (LLM) is an AI system trained on vast amounts of text data to understand and generate human-like language for tasks such as answering questions, writing, and conversation.'},\n",
       " {'role': 'user', 'content': 'Write another sentence'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d940a7-bdc7-4446-9c34-6656c10ab800",
   "metadata": {},
   "source": [
    "# Infinite Chat \n",
    "\n",
    "Simple chat implemented with a infinite loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af906b0b-3508-4a4d-9a5c-6b498c18bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "# Looping forever\n",
    "while True:\n",
    "    \n",
    "    # Get user input\n",
    "    user_input = input(\"> \") \n",
    "    print(\">\", user_input)\n",
    "\n",
    "    # Add user input to the list of messages\n",
    "    add_user_message(messages, user_input)\n",
    "\n",
    "    # Call Claude\n",
    "    answer = chat(messages)\n",
    "\n",
    "    # Add generated text to messages\n",
    "    add_assistant_message(messages, answer)\n",
    "\n",
    "    # Print response\n",
    "    print(\"---\\n\", answer, \"\\n---\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da148d2-2694-458e-bb23-a9eaff0917d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "claude-course-kernel",
   "language": "python",
   "name": "claude-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

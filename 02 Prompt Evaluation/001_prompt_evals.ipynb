{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5437be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env variables and create client\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic()\n",
    "model = \"claude-haiku-4-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b0d8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    if stop_sequences:\n",
    "        params[\"stop_sequences\"] = stop_sequences\n",
    "\n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e788701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    prompt = \"\"\"\n",
    "Generate a evaluation dataset for a prompt evaluation. The dataset will be used to evaluate prompts\n",
    "that generate Python, JSON, or Regex specifically for AWS-related tasks. Generate an array of JSON objects,\n",
    "each representing task that requires Python, JSON, or a Regex to complete.\n",
    "\n",
    "Example output:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"task\": \"Description of task\",\n",
    "        \"format\": \"json\" or \"python\" or \"regex\",\n",
    "        \"solution_criteria\": \"Key criteria for evaluating the solution\"\n",
    "    },\n",
    "    ...additional\n",
    "]\n",
    "```\n",
    "\n",
    "* Focus on tasks that can be solved by writing a single Python function, a single JSON object, or a regular expression.\n",
    "* Focus on tasks that do not require writing much code\n",
    "\n",
    "Please generate 3 objects.\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6f20d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'task': 'Parse an AWS CloudWatch log entry and extract the timestamp, log level, and message using a regular expression',\n",
       "  'format': 'regex',\n",
       "  'solution_criteria': 'The regex should correctly capture three groups: (1) ISO 8601 timestamp, (2) log level (ERROR, WARN, INFO, DEBUG), and (3) the remaining message text. Should handle variations in timestamp formats.'},\n",
       " {'task': 'Write a Python function that takes an AWS S3 object key path and returns a dictionary with the bucket name, folder structure, and file name as separate components',\n",
       "  'format': 'python',\n",
       "  'solution_criteria': 'The function should split the S3 path correctly, return a dict with keys for bucket, folders (as list), and filename. Handle edge cases like paths with no folders or trailing slashes.'},\n",
       " {'task': 'Create a JSON CloudFormation template snippet for an IAM role that allows an EC2 instance to read objects from a specific S3 bucket',\n",
       "  'format': 'json',\n",
       "  'solution_criteria': 'Valid JSON with proper IAM role definition, trust policy for EC2, and an inline policy granting s3:GetObject permissions scoped to a specific bucket ARN. Must follow CloudFormation syntax.'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = generate_dataset()\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c790a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc323f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(test_case):\n",
    "    \"\"\"Merges the prompt and test case input, then returns the result\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Please solve the following task:\n",
    "\n",
    "{test_case[\"task\"]}\n",
    "\n",
    "* Respond only with Python, JSON, or a plain Regex\n",
    "* Do not add any comments or commentary or explanation\n",
    "\"\"\"\n",
    "    \n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assistant_message(messages, \"```code\")\n",
    "    output = chat(messages, stop_sequences=[\"```\"])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6da4577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_by_model(test_case, output):\n",
    "\n",
    "    eval_prompt = f\"\"\"\n",
    "You are an expert AWS code reviewer. Your task is to evaluate the following AI-generated solution.\n",
    "\n",
    "Original Task:\n",
    "<task>\n",
    "{test_case[\"task\"]}\n",
    "</task>\n",
    "\n",
    "Solution to Evaluate:\n",
    "<solution>\n",
    "{output}\n",
    "</solution>\n",
    "\n",
    "Criteria you should use to evaluate the solution:\n",
    "<criteria>\n",
    "{test_case[\"solution_criteria\"]}\n",
    "</criteria>\n",
    "\n",
    "Output Format\n",
    "Provide your evaluation as a structured JSON object with the following fields, in this specific order:\n",
    "- \"strengths\": An array of 1-3 key strengths\n",
    "- \"weaknesses\": An array of 1-3 key areas for improvement\n",
    "- \"reasoning\": A concise explanation of your overall assessment\n",
    "- \"score\": A number between 1-10\n",
    "\n",
    "Respond with JSON. Keep your response concise and direct.\n",
    "Example response shape:\n",
    "{{\n",
    "    \"strengths\": string[],\n",
    "    \"weaknesses\": string[],\n",
    "    \"reasoning\": string,\n",
    "    \"score\": number\n",
    "}}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, eval_prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    eval_text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(eval_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "486481e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import ast\n",
    "\n",
    "\n",
    "def validate_json(text):\n",
    "    try:\n",
    "        json.loads(text.strip())\n",
    "        return 10\n",
    "    except json.JSONDecodeError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def validate_python(text):\n",
    "    try:\n",
    "        ast.parse(text.strip())\n",
    "        return 10\n",
    "    except SyntaxError:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def validate_regex(text):\n",
    "    try:\n",
    "        re.compile(text.strip())\n",
    "        return 10\n",
    "    except re.error:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def grade_syntax(response, test_case):\n",
    "    format = test_case[\"format\"]\n",
    "    if format == \"json\":\n",
    "        return validate_json(response)\n",
    "    elif format == \"python\":\n",
    "        return validate_python(response)\n",
    "    else:\n",
    "        return validate_regex(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "435390c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_case(test_case):\n",
    "    \"\"\"Calls run_prompt, then grades the results\"\"\"\n",
    "\n",
    "    output = run_prompt(test_case)\n",
    "\n",
    "    model_grade = grade_by_model(test_case, output)\n",
    "    model_score = model_grade[\"score\"]\n",
    "    reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "    syntax_score = grade_syntax(output, test_case)\n",
    "\n",
    "    score = (model_score + syntax_score) / 2\n",
    "\n",
    "    return {\n",
    "        \"output\": output,\n",
    "        \"test_case\": test_case,\n",
    "        \"score\": score,\n",
    "        \"reasoning\": reasoning\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "964ffe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "def run_eval(dataset):\n",
    "    \"\"\"Loads the dataset and calls run_test_case with each case\"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "\n",
    "    average_score = mean([result[\"score\"] for result in results])\n",
    "    print(f\"Average score: {average_score}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "616d449b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 8.5\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4925a447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"output\": \"\\nimport re\\nimport json\\n\\ndef parse_cloudwatch_log(log_entry):\\n    pattern = r'(\\\\d{4}-\\\\d{2}-\\\\d{2}T\\\\d{2}:\\\\d{2}:\\\\d{2}\\\\.\\\\d{3}Z)\\\\s+(\\\\w+)\\\\s+(.*)'\\n    match = re.match(pattern, log_entry)\\n    \\n    if match:\\n        return {\\n            \\\"timestamp\\\": match.group(1),\\n            \\\"log_level\\\": match.group(2),\\n            \\\"message\\\": match.group(3)\\n        }\\n    return None\\n\\nlog_entry = \\\"2024-01-15T10:30:45.123Z ERROR Connection timeout occurred\\\"\\nresult = parse_cloudwatch_log(log_entry)\\nprint(json.dumps(result, indent=2))\\n\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Parse an AWS CloudWatch log entry and extract the timestamp, log level, and message using a regular expression\",\n",
      "      \"format\": \"regex\",\n",
      "      \"solution_criteria\": \"The regex should correctly capture three groups: (1) ISO 8601 timestamp, (2) log level (ERROR, WARN, INFO, DEBUG), and (3) the remaining message text. Should handle variations in timestamp formats.\"\n",
      "    },\n",
      "    \"score\": 8.0,\n",
      "    \"reasoning\": \"The solution successfully handles the basic case shown in the example but lacks robustness for real-world CloudWatch log variations. The regex is too strict for some formats (milliseconds required) while being too loose for log levels (accepts any word, not just valid levels). For production use, the log level should be constrained to known values, and timestamp handling should be more flexible to accommodate different CloudWatch log formats.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"\\nimport re\\n\\ndef parse_s3_path(s3_path):\\n    \\\"\\\"\\\"\\n    Parse an S3 object key path and return components.\\n    \\n    Args:\\n        s3_path: S3 path in format 's3://bucket-name/path/to/file.ext'\\n                 or 'bucket-name/path/to/file.ext'\\n    \\n    Returns:\\n        Dictionary with keys: 'bucket', 'folders', 'filename'\\n    \\\"\\\"\\\"\\n    # Handle s3:// prefix if present\\n    if s3_path.startswith('s3://'):\\n        s3_path = s3_path[5:]\\n    \\n    # Split by first forward slash to separate bucket from path\\n    parts = s3_path.split('/', 1)\\n    bucket = parts[0]\\n    \\n    if len(parts) == 1:\\n        # Only bucket, no path\\n        return {\\n            'bucket': bucket,\\n            'folders': [],\\n            'filename': ''\\n        }\\n    \\n    path = parts[1]\\n    \\n    # Split path into folder structure and filename\\n    path_parts = path.split('/')\\n    filename = path_parts[-1]\\n    folders = path_parts[:-1]\\n    \\n    return {\\n        'bucket': bucket,\\n        'folders': folders,\\n        'filename': filename\\n    }\\n\\n\\n# Test cases\\ntest_paths = [\\n    's3://my-bucket/path/to/file.txt',\\n    'my-bucket/path/to/file.txt',\\n    's3://bucket/file.txt',\\n    'bucket/file.txt',\\n    's3://bucket/',\\n    'bucket',\\n]\\n\\nfor test_path in test_paths:\\n    print(f\\\"{test_path} -> {parse_s3_path(test_path)}\\\")\\n\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Write a Python function that takes an AWS S3 object key path and returns a dictionary with the bucket name, folder structure, and file name as separate components\",\n",
      "      \"format\": \"python\",\n",
      "      \"solution_criteria\": \"The function should split the S3 path correctly, return a dict with keys for bucket, folders (as list), and filename. Handle edge cases like paths with no folders or trailing slashes.\"\n",
      "    },\n",
      "    \"score\": 8.5,\n",
      "    \"reasoning\": \"The solution successfully implements the core functionality for typical S3 paths and handles the basic happy path well. However, there are edge case issues with trailing slashes and a lack of input validation. The unused regex import suggests incomplete implementation or copy-paste artifact. For production use, the function should strip trailing slashes before processing and validate inputs. The core logic is sound but needs refinement for robustness.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"\\n{\\n  \\\"AWSTemplateFormatVersion\\\": \\\"2010-09-09\\\",\\n  \\\"Resources\\\": {\\n    \\\"EC2S3ReadRole\\\": {\\n      \\\"Type\\\": \\\"AWS::IAM::Role\\\",\\n      \\\"Properties\\\": {\\n        \\\"AssumeRolePolicyDocument\\\": {\\n          \\\"Version\\\": \\\"2012-10-17\\\",\\n          \\\"Statement\\\": [\\n            {\\n              \\\"Effect\\\": \\\"Allow\\\",\\n              \\\"Principal\\\": {\\n                \\\"Service\\\": \\\"ec2.amazonaws.com\\\"\\n              },\\n              \\\"Action\\\": \\\"sts:AssumeRole\\\"\\n            }\\n          ]\\n        },\\n        \\\"Policies\\\": [\\n          {\\n            \\\"PolicyName\\\": \\\"S3ReadPolicy\\\",\\n            \\\"PolicyDocument\\\": {\\n              \\\"Version\\\": \\\"2012-10-17\\\",\\n              \\\"Statement\\\": [\\n                {\\n                  \\\"Effect\\\": \\\"Allow\\\",\\n                  \\\"Action\\\": [\\n                    \\\"s3:GetObject\\\",\\n                    \\\"s3:ListBucket\\\"\\n                  ],\\n                  \\\"Resource\\\": [\\n                    \\\"arn:aws:s3:::my-bucket\\\",\\n                    \\\"arn:aws:s3:::my-bucket/*\\\"\\n                  ]\\n                }\\n              ]\\n            }\\n          }\\n        ]\\n      }\\n    },\\n    \\\"EC2S3ReadInstanceProfile\\\": {\\n      \\\"Type\\\": \\\"AWS::IAM::InstanceProfile\\\",\\n      \\\"Properties\\\": {\\n        \\\"Roles\\\": [\\n          {\\n            \\\"Ref\\\": \\\"EC2S3ReadRole\\\"\\n          }\\n        ]\\n      }\\n    }\\n  }\\n}\\n\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Create a JSON CloudFormation template snippet for an IAM role that allows an EC2 instance to read objects from a specific S3 bucket\",\n",
      "      \"format\": \"json\",\n",
      "      \"solution_criteria\": \"Valid JSON with proper IAM role definition, trust policy for EC2, and an inline policy granting s3:GetObject permissions scoped to a specific bucket ARN. Must follow CloudFormation syntax.\"\n",
      "    },\n",
      "    \"score\": 9.0,\n",
      "    \"reasoning\": \"The solution successfully meets the core requirements: it's valid JSON, defines a proper IAM role with EC2 trust policy, includes an InstanceProfile (essential for EC2 to use the role), and grants s3:GetObject permissions scoped to a specific bucket. The main limitation is the hardcoded bucket name rather than using CloudFormation parameters, which would be a production best practice. The inclusion of s3:ListBucket is reasonable for practical S3 access but slightly exceeds the minimal scope requested.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7696d91e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "claude-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
